{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cec53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV head:\n",
      "                 image label\n",
      "0  Img/img001-001.png     0\n",
      "1  Img/img001-002.png     0\n",
      "2  Img/img001-003.png     0\n",
      "3  Img/img001-004.png     0\n",
      "4  Img/img001-005.png     0\n",
      "✅ Loaded 3410 images\n",
      "Shapes: (3410, 784) (3410,)\n",
      "Unique labels: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H'\n",
      " 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z'\n",
      " 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
      " 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
      "Train set: (2728, 784) Test set: (682, 784)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_path = \"Dataset/\"\n",
    "\n",
    "def load_dataset(folder_path, csv_name=\"english.csv\", img_folder=\"Img\", img_size=(28,28)):\n",
    "    # Load CSV\n",
    "    csv_path = os.path.join(folder_path, csv_name)\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    print(\"CSV head:\\n\", df.head())  # Debug: show first rows\n",
    "\n",
    "    X, y = [], []\n",
    "    for _, row in df.iterrows():\n",
    "        \n",
    "        if \"filename\" in df.columns and \"label\" in df.columns:\n",
    "            fname, label = row[\"filename\"], row[\"label\"]\n",
    "        else:\n",
    "            fname, label = row.iloc[0], row.iloc[1]\n",
    "\n",
    "        fpath = os.path.join(folder_path,fname)\n",
    "        \n",
    "        if os.path.exists(fpath):\n",
    "            img = Image.open(fpath).convert('L').resize(img_size)\n",
    "            arr = np.array(img, dtype=np.float32).ravel() / 255.0\n",
    "            X.append(arr)\n",
    "            y.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: File {fpath} not found, skipping.\")\n",
    "\n",
    "    print(f\"✅ Loaded {len(X)} images\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# Load data\n",
    "X, y = load_dataset(dataset_path)\n",
    "\n",
    "# Check before splitting\n",
    "print(\"Shapes:\", X.shape, y.shape)\n",
    "print(\"Unique labels:\", np.unique(y))\n",
    "\n",
    "# Train-test split\n",
    "if len(X) > 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    print(\"Train set:\", X_train.shape, \"Test set:\", X_test.shape)\n",
    "else:\n",
    "    print(\"❌ No samples loaded. Please check CSV/image paths.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa1a38c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus Vivobook\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0284 - loss: 4.1734 - val_accuracy: 0.0604 - val_loss: 4.0282\n",
      "Epoch 2/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1261 - loss: 3.7852 - val_accuracy: 0.1264 - val_loss: 3.7404\n",
      "Epoch 3/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2282 - loss: 3.2970 - val_accuracy: 0.2070 - val_loss: 3.3515\n",
      "Epoch 4/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3387 - loss: 2.6796 - val_accuracy: 0.2363 - val_loss: 3.0766\n",
      "Epoch 5/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4393 - loss: 2.2111 - val_accuracy: 0.2839 - val_loss: 2.8961\n",
      "Epoch 6/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5093 - loss: 1.9188 - val_accuracy: 0.3150 - val_loss: 2.7678\n",
      "Epoch 7/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5604 - loss: 1.7096 - val_accuracy: 0.3370 - val_loss: 2.7267\n",
      "Epoch 8/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6113 - loss: 1.5130 - val_accuracy: 0.3443 - val_loss: 2.7259\n",
      "Epoch 9/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6541 - loss: 1.3806 - val_accuracy: 0.3462 - val_loss: 2.7113\n",
      "Epoch 10/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6637 - loss: 1.2948 - val_accuracy: 0.3608 - val_loss: 2.7109\n",
      "Epoch 11/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7073 - loss: 1.1227 - val_accuracy: 0.3663 - val_loss: 2.7289\n",
      "Epoch 12/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 1.0871 - val_accuracy: 0.3791 - val_loss: 2.7246\n",
      "Epoch 13/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 1.0047 - val_accuracy: 0.3773 - val_loss: 2.7428\n",
      "Epoch 14/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7651 - loss: 0.8803 - val_accuracy: 0.3718 - val_loss: 2.7956\n",
      "Epoch 15/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7991 - loss: 0.8236 - val_accuracy: 0.3791 - val_loss: 2.7859\n",
      "Epoch 16/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.7464 - val_accuracy: 0.3828 - val_loss: 2.8143\n",
      "Epoch 17/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8101 - loss: 0.7477 - val_accuracy: 0.3828 - val_loss: 2.8589\n",
      "Epoch 18/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.7011 - val_accuracy: 0.3919 - val_loss: 2.9069\n",
      "Epoch 19/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.6255 - val_accuracy: 0.3864 - val_loss: 2.9356\n",
      "Epoch 20/20\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.5704 - val_accuracy: 0.3810 - val_loss: 2.9619\n",
      "MLP Test Accuracy: 0.3827\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Prepare Data\n",
    "# ---------------------------\n",
    "# Assume you already have X, y from your dataset\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Build Simple MLP\n",
    "# ---------------------------\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation=\"relu\"))   # hidden layer 1\n",
    "model.add(Dense(32, activation=\"relu\"))                               # hidden layer 2\n",
    "model.add(Dense(len(np.unique(y_train)), activation=\"softmax\"))       # output layer\n",
    "\n",
    "# Compile with default optimizer\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"MLP Test Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22909ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: LR=0.001, Batch=16, Opt=sgd, Act=relu\n",
      " → Accuracy: 0.0425\n",
      "Training: LR=0.001, Batch=16, Opt=sgd, Act=tanh\n",
      " → Accuracy: 0.0718\n",
      "Training: LR=0.001, Batch=16, Opt=adam, Act=relu\n",
      " → Accuracy: 0.4208\n",
      "Training: LR=0.001, Batch=16, Opt=adam, Act=tanh\n",
      " → Accuracy: 0.3607\n",
      "Training: LR=0.001, Batch=32, Opt=sgd, Act=relu\n",
      " → Accuracy: 0.0103\n",
      "Training: LR=0.001, Batch=32, Opt=sgd, Act=tanh\n",
      " → Accuracy: 0.0455\n",
      "Training: LR=0.001, Batch=32, Opt=adam, Act=relu\n",
      " → Accuracy: 0.3974\n",
      "Training: LR=0.001, Batch=32, Opt=adam, Act=tanh\n",
      " → Accuracy: 0.3328\n",
      "Training: LR=0.001, Batch=64, Opt=sgd, Act=relu\n",
      " → Accuracy: 0.0308\n",
      "Training: LR=0.001, Batch=64, Opt=sgd, Act=tanh\n",
      " → Accuracy: 0.0235\n",
      "Training: LR=0.001, Batch=64, Opt=adam, Act=relu\n",
      " → Accuracy: 0.3856\n",
      "Training: LR=0.001, Batch=64, Opt=adam, Act=tanh\n",
      " → Accuracy: 0.3138\n",
      "Training: LR=0.01, Batch=16, Opt=sgd, Act=relu\n",
      " → Accuracy: 0.2991\n",
      "Training: LR=0.01, Batch=16, Opt=sgd, Act=tanh\n",
      " → Accuracy: 0.2493\n",
      "Training: LR=0.01, Batch=16, Opt=adam, Act=relu\n",
      " → Accuracy: 0.2727\n",
      "Training: LR=0.01, Batch=16, Opt=adam, Act=tanh\n",
      " → Accuracy: 0.3079\n",
      "Training: LR=0.01, Batch=32, Opt=sgd, Act=relu\n",
      " → Accuracy: 0.1422\n",
      "Training: LR=0.01, Batch=32, Opt=sgd, Act=tanh\n",
      " → Accuracy: 0.1877\n",
      "Training: LR=0.01, Batch=32, Opt=adam, Act=relu\n",
      " → Accuracy: 0.3343\n",
      "Training: LR=0.01, Batch=32, Opt=adam, Act=tanh\n",
      " → Accuracy: 0.3358\n",
      "Training: LR=0.01, Batch=64, Opt=sgd, Act=relu\n",
      " → Accuracy: 0.0704\n",
      "Training: LR=0.01, Batch=64, Opt=sgd, Act=tanh\n",
      " → Accuracy: 0.1202\n",
      "Training: LR=0.01, Batch=64, Opt=adam, Act=relu\n",
      " → Accuracy: 0.3299\n",
      "Training: LR=0.01, Batch=64, Opt=adam, Act=tanh\n",
      " → Accuracy: 0.3255\n",
      "Training: LR=0.1, Batch=16, Opt=sgd, Act=relu\n",
      " → Accuracy: 0.2419\n",
      "Training: LR=0.1, Batch=16, Opt=sgd, Act=tanh\n",
      " → Accuracy: 0.3666\n",
      "Training: LR=0.1, Batch=16, Opt=adam, Act=relu\n",
      " → Accuracy: 0.0117\n",
      "Training: LR=0.1, Batch=16, Opt=adam, Act=tanh\n",
      " → Accuracy: 0.1085\n",
      "Training: LR=0.1, Batch=32, Opt=sgd, Act=relu\n",
      " → Accuracy: 0.3167\n",
      "Training: LR=0.1, Batch=32, Opt=sgd, Act=tanh\n",
      " → Accuracy: 0.3460\n",
      "Training: LR=0.1, Batch=32, Opt=adam, Act=relu\n",
      " → Accuracy: 0.0132\n",
      "Training: LR=0.1, Batch=32, Opt=adam, Act=tanh\n",
      " → Accuracy: 0.0924\n",
      "Training: LR=0.1, Batch=64, Opt=sgd, Act=relu\n",
      " → Accuracy: 0.3519\n",
      "Training: LR=0.1, Batch=64, Opt=sgd, Act=tanh\n",
      " → Accuracy: 0.3182\n",
      "Training: LR=0.1, Batch=64, Opt=adam, Act=relu\n",
      " → Accuracy: 0.0088\n",
      "Training: LR=0.1, Batch=64, Opt=adam, Act=tanh\n",
      " → Accuracy: 0.1305\n",
      "\n",
      "Best Hyperparameters: (0.001, 16, 'adam', 'relu') with Accuracy: 0.42082110047340393\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "def build_mlp(input_dim, n_classes, hidden_layers=[64, 32], activation=\"relu\", optimizer=\"adam\", lr=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layers[0], input_dim=input_dim, activation=activation))\n",
    "    for units in hidden_layers[1:]:\n",
    "        model.add(Dense(units, activation=activation))\n",
    "    model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "    \n",
    "    if optimizer == \"sgd\":\n",
    "        opt = SGD(learning_rate=lr)\n",
    "    elif optimizer == \"adam\":\n",
    "        opt = Adam(learning_rate=lr)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer\")\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [16, 32, 64]\n",
    "optimizers = [\"sgd\", \"adam\"]\n",
    "activations = [\"relu\", \"tanh\"]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch in batch_sizes:\n",
    "        for opt in optimizers:\n",
    "            for act in activations:\n",
    "                print(f\"Training: LR={lr}, Batch={batch}, Opt={opt}, Act={act}\")\n",
    "                model = build_mlp(input_dim=X_train.shape[1],\n",
    "                                  n_classes=len(np.unique(y_train)),\n",
    "                                  hidden_layers=[64, 32],\n",
    "                                  activation=act,\n",
    "                                  optimizer=opt,\n",
    "                                  lr=lr)\n",
    "                history = model.fit(X_train, y_train, epochs=20, batch_size=batch,\n",
    "                                    validation_split=0.2, verbose=0)\n",
    "                \n",
    "                _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "                results[(lr, batch, opt, act)] = acc\n",
    "                print(f\" → Accuracy: {acc:.4f}\")\n",
    "\n",
    "best_config = max(results, key=results.get)\n",
    "print(\"\\nBest Hyperparameters:\", best_config, \"with Accuracy:\", results[best_config])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f539524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
